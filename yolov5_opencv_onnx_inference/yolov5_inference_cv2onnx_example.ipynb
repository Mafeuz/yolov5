{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "859c67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "print(f'Number of GPUs available: {cv2.cuda.getCudaEnabledDeviceCount()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ac37307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov5_processing(img, net, input_shape):\n",
    "    \n",
    "    H, W = input_shape\n",
    "    \n",
    "    # Transform img to blob format (with normalization)\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255,  (W, H), [0,0,0], 1, crop=False)\n",
    "    \n",
    "    # Get output from img input:\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "    \n",
    "    time, _ = net.getPerfProfile()\n",
    "    info = f'Inference time: {(time*1000.0/cv2.getTickFrequency()):.2f} ms'\n",
    "    print(info)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37cfd89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(img, label_text, x1, y1):\n",
    "    \n",
    "    # Get label dimesions:\n",
    "    text_size     = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    dim, baseline = text_size[0], text_size[1]\n",
    "    \n",
    "    # Draw label:\n",
    "    cv2.rectangle(img, (x1, y1), (x1 + dim[0], y1 + dim[1] + baseline), (0,0,0), cv2.FILLED);\n",
    "    cv2.putText(img, label_text, (x1, y1 + dim[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10686097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov5_inference_cv2onnx(img, net,  input_shape, classes, conf_thresh=0.3, cls_thresh=0.1, nms_thresh=0.2):\n",
    "    \n",
    "    outputs = yolov5_processing(img, net, input_shape=input_shape)\n",
    "    \n",
    "    # Output objs lists:\n",
    "    bboxes         = []\n",
    "    class_ids      = []\n",
    "    confidences    = []\n",
    "    img_detections = []\n",
    "    \n",
    "    # Detections:\n",
    "    detections = outputs[0].shape[1]\n",
    "    \n",
    "    # Loops over detections:\n",
    "    for d_index in range(detections):\n",
    "        detection  = outputs[0][0][d_index]\n",
    "        confidence = detection[4]\n",
    "        \n",
    "        # Filter detection by confidence and class score:\n",
    "        if confidence >= conf_thresh:\n",
    "        \n",
    "            # Get class from highest score detected:\n",
    "            classes_scores = detection[5:]\n",
    "            class_id = np.argmax(classes_scores)\n",
    "                \n",
    "            #  Continue if the class score is above threshold.\n",
    "            if (classes_scores[class_id] > cls_thresh):\n",
    "                confidences.append(confidence)\n",
    "                class_ids.append(class_id)\n",
    "                    \n",
    "                # Extracting bbox:\n",
    "                cX, cY, w, h = detection[0], detection[1], detection[2], detection[3]\n",
    "                x1     = int((cX - w/2)*(img.shape[1]/input_shape[1]))\n",
    "                y1     = int((cY - h/2)*(img.shape[0]/input_shape[0]))\n",
    "                width  = int(w*(img.shape[1]/input_shape[1]))\n",
    "                height = int(h*(img.shape[0]/input_shape[0]))\n",
    "                bbox = np.array([x1, y1, width, height])\n",
    "                bboxes.append(bbox)\n",
    "                   \n",
    "    # Removing low conf overlaping bboxes with cv2 non-maxima-supression:\n",
    "    nms_indeces = cv2.dnn.NMSBoxes(bboxes, confidences, conf_thresh, nms_thresh)\n",
    "    \n",
    "    for i in nms_indeces:\n",
    "        \n",
    "        bbox = bboxes[i]\n",
    "        \n",
    "        x1 = bbox[0] \n",
    "        y1 = bbox[1]\n",
    "        x2 = (x1 + bbox[2])\n",
    "        y2 = (y1 + bbox[3])\n",
    "        \n",
    "        # Draw bounding box and label:     \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 3)\n",
    "        label_text = f'{classes[class_ids[i]]} {confidences[i]:.2f}'           \n",
    "        draw_label(img, label_text, x1, y1)\n",
    "        \n",
    "        # Add to img detections output:\n",
    "        img_detections.append([bbox, confidences[i], class_ids[i]])\n",
    "    \n",
    "    return img, img_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c46822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 1782.26 ms\n",
      "Detections: [[array([1524,   61,  420,  859]), 0.91709656, 17], [array([ 84, 129, 526, 778]), 0.87771267, 16], [array([806,  68, 438, 854]), 0.851154, 17], [array([1235,  353,  331,  560]), 0.70271075, 15], [array([581, 382, 259, 537]), 0.4275494, 27]]\n"
     ]
    }
   ],
   "source": [
    "# Load class names:\n",
    "coco_classes =  ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush']\n",
    "\n",
    "# Loading onnx model:\n",
    "weights = \"yolov5m6_coco.onnx\"\n",
    "net = cv2.dnn.readNet(weights)\n",
    "\n",
    "# Use GPU:\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Load image.\n",
    "img = cv2.imread('dogs_cats.jpg')\n",
    "\n",
    "# Processing:\n",
    "img_output, img_detections = yolov5_inference_cv2onnx(img.copy(), net, input_shape=(1280, 1280), \n",
    "                            classes=coco_classes, conf_thresh=0.3, cls_thresh=0.1, nms_thresh=0.2)\n",
    "\n",
    "print('Detections:', img_detections)\n",
    "img_output = cv2.resize(img_output, (1000, 640))\n",
    "cv2.imshow('Output', img_output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99b126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682f9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
